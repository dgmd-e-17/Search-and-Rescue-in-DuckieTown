The AWS workflow has three primary componets described below:

1) Robot / Client Upload Software: This code (upload_aws_py) is executed on the robot. Once the robot detects and categorizes an image as a potential disaster or emergency situation, the robot will use the client software to hit an API endpoint which is managed via AWS API Gateway. The gateway passes the robot request to a Lambda function described below

2) Lambda s3 Upload Function: This code (lambda_s3_upload.py) is written as a serverless function which awaits a call from our API Gateway. The function then returns a pre-signed, secure URL back to the gateway which is then passed back to the robot. The logic written in upload_aws_py then accepts the pre-signed URL, converts the image for network trasmit and then tranfser the image and meta data back to the API gateway and the Lambda function will then complete the upload into s3 and send confirmation back upon succesful upload or returns an exception with error tracing.

3) Commnand Center Reporting and Analysis Software: This code is written in Python and deployed as a Flask application which provides several key capabilities including real-time deep analysis of the uploaded image using AWS AI Rekognition services which will provide labeling and additional details of the disaster or emrgency situation. The Flask application also provides a user interface for operator use including real-time updates of all images stored in the s3 bucket and determination if the image is a disaster or not based on pre-defined disaster criteria based on labels extracted from the image. It also provides ability for the operator to view the image with bounding boxes and also request emergency response workflow, which are generated using another layer of object detection and classification leveraging TensorFlow MASK R-CNN 50 Layer neural network.
